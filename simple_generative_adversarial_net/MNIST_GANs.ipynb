{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "MNIST_GANs.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyNQ+nL/AHIolIF4/nwfWfDr",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/s-mostafa-a/pytorch_learning/blob/master/simple_generative_adversarial_net/MNIST_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iD-_koyzkAm2",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "import torch\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "\n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield self.to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def to_device(self, data, device):\n",
    "        if isinstance(data, (list, tuple)):\n",
    "            return [self.to_device(x, device) for x in data]\n",
    "        return data.to(device, non_blocking=True)\n",
    "\n",
    "class MNIST_GANS:\n",
    "    def __init__(self, dataset, image_size, device, num_epochs=50, loss_function=nn.BCELoss(), batch_size=100,\n",
    "                 hidden_size=2561, latent_size=64):\n",
    "        self.device = device\n",
    "        bare_data_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "        self.data_loader = DeviceDataLoader(bare_data_loader, device)\n",
    "        self.loss_function = loss_function\n",
    "        self.hidden_size = hidden_size\n",
    "        self.latent_size = latent_size\n",
    "        self.batch_size = batch_size\n",
    "        self.D = nn.Sequential(\n",
    "            nn.Linear(image_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_size, 1),\n",
    "            nn.Sigmoid())\n",
    "        self.G = nn.Sequential(\n",
    "            nn.Linear(latent_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, image_size),\n",
    "            nn.Tanh())\n",
    "        self.d_optimizer = torch.optim.Adam(self.D.parameters(), lr=0.0002)\n",
    "        self.g_optimizer = torch.optim.Adam(self.G.parameters(), lr=0.0002)\n",
    "        self.sample_dir = './../data/samples'\n",
    "        if not os.path.exists(self.sample_dir):\n",
    "            os.makedirs(self.sample_dir)\n",
    "        if self.device:\n",
    "          self.G.to(device)\n",
    "          self.D.to(device)\n",
    "        self.sample_vectors = torch.randn(self.batch_size, self.latent_size).to(self.device)\n",
    "        self.num_epochs = num_epochs\n",
    "\n",
    "    @staticmethod\n",
    "    def denormalize(x):\n",
    "        out = (x + 1) / 2\n",
    "        return out.clamp(0, 1)\n",
    "\n",
    "    def reset_grad(self):\n",
    "        self.d_optimizer.zero_grad()\n",
    "        self.g_optimizer.zero_grad()\n",
    "\n",
    "    def train_discriminator(self, images):\n",
    "        real_labels = torch.ones(self.batch_size, 1).to(self.device)\n",
    "        fake_labels = torch.zeros(self.batch_size, 1).to(self.device)\n",
    "\n",
    "        outputs = self.D(images)\n",
    "        d_loss_real = self.loss_function(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "\n",
    "        new_sample_vectors = torch.randn(self.batch_size, self.latent_size).to(self.device)\n",
    "        fake_images = self.G(new_sample_vectors)\n",
    "        outputs = self.D(fake_images)\n",
    "        d_loss_fake = self.loss_function(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        self.reset_grad()\n",
    "        d_loss.backward()\n",
    "        self.d_optimizer.step()\n",
    "\n",
    "        return d_loss, real_score, fake_score\n",
    "\n",
    "    def train_generator(self):\n",
    "        new_sample_vectors = torch.randn(self.batch_size, self.latent_size).to(self.device)\n",
    "        fake_images = self.G(new_sample_vectors)\n",
    "        labels = torch.ones(self.batch_size, 1).to(self.device)\n",
    "        g_loss = self.loss_function(self.D(fake_images), labels)\n",
    "\n",
    "        self.reset_grad()\n",
    "        g_loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "        return g_loss, fake_images\n",
    "\n",
    "    def save_fake_images(self, index):\n",
    "        fake_images = self.G(self.sample_vectors)\n",
    "        fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "        fake_fname = 'fake_images-{0:0=4d}.png'.format(index)\n",
    "        print('Saving', fake_fname)\n",
    "        save_image(self.denormalize(fake_images), os.path.join(self.sample_dir, fake_fname),\n",
    "                   nrow=10)\n",
    "\n",
    "    def run(self):\n",
    "        total_step = len(self.data_loader)\n",
    "        d_losses, g_losses, real_scores, fake_scores = [], [], [], []\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for i, (images, _) in enumerate(self.data_loader):\n",
    "                images = images.reshape(self.batch_size, -1)\n",
    "\n",
    "                d_loss, real_score, fake_score = self.train_discriminator(images)\n",
    "                g_loss, fake_images = self.train_generator()\n",
    "\n",
    "                if (i + 1) % 600 == 0:\n",
    "                    d_losses.append(d_loss.item())\n",
    "                    g_losses.append(g_loss.item())\n",
    "                    real_scores.append(real_score.mean().item())\n",
    "                    fake_scores.append(fake_score.mean().item())\n",
    "                    print(f'''Epoch [{epoch}/{self.num_epochs}], Step [{i + 1}/{\n",
    "                    total_step}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}, D(x): {\n",
    "                    real_score.mean().item():.2f}, D(G(z)): {fake_score.mean().item():.2f}''')\n",
    "            self.save_fake_images(epoch + 1)\n",
    "\n",
    "\n",
    "image_size = 784\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "mnist = MNIST(root='./../data', train=True, download=True, transform=Compose([ToTensor(), Normalize(mean=(0.5,), std=(0.5,))]))\n",
    "gans = MNIST_GANS(dataset=mnist, image_size=image_size, device=device)\n",
    "gans.run()\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\nProcessing...\n",
      "Done!\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "\r0.0%",
      "\r0.1%",
      "\r0.2%",
      "\r0.2%",
      "\r0.3%",
      "\r0.4%",
      "\r0.5%",
      "\r0.6%",
      "\r0.7%",
      "\r0.7%",
      "\r0.8%",
      "\r0.9%",
      "\r1.0%",
      "\r1.1%",
      "\r1.2%",
      "\r1.2%",
      "\r1.3%",
      "\r1.4%",
      "\r1.5%",
      "\r1.6%",
      "\r1.7%",
      "\r1.7%",
      "\r1.8%",
      "\r1.9%",
      "\r2.0%",
      "\r2.1%",
      "\r2.1%",
      "\r2.2%",
      "\r2.3%",
      "\r2.4%",
      "\r2.5%",
      "\r2.6%",
      "\r2.6%",
      "\r2.7%",
      "\r2.8%",
      "\r2.9%",
      "\r3.0%",
      "\r3.1%",
      "\r3.1%",
      "\r3.2%",
      "\r3.3%",
      "\r3.4%",
      "\r3.5%",
      "\r3.6%",
      "\r3.6%",
      "\r3.7%",
      "\r3.8%",
      "\r3.9%",
      "\r4.0%",
      "\r4.0%",
      "\r4.1%",
      "\r4.2%",
      "\r4.3%",
      "\r4.4%",
      "\r4.5%",
      "\r4.5%",
      "\r4.6%",
      "\r4.7%",
      "\r4.8%",
      "\r4.9%",
      "\r5.0%",
      "\r5.0%",
      "\r5.1%",
      "\r5.2%",
      "\r5.3%",
      "\r5.4%",
      "\r5.5%",
      "\r5.5%",
      "\r5.6%",
      "\r5.7%",
      "\r5.8%",
      "\r5.9%",
      "\r6.0%",
      "\r6.0%",
      "\r6.1%",
      "\r6.2%",
      "\r6.3%",
      "\r6.4%",
      "\r6.4%",
      "\r6.5%",
      "\r6.6%",
      "\r6.7%",
      "\r6.8%",
      "\r6.9%",
      "\r6.9%",
      "\r7.0%",
      "\r7.1%",
      "\r7.2%",
      "\r7.3%",
      "\r7.4%",
      "\r7.4%",
      "\r7.5%",
      "\r7.6%",
      "\r7.7%",
      "\r7.8%",
      "\r7.9%",
      "\r7.9%",
      "\r8.0%",
      "\r8.1%",
      "\r8.2%",
      "\r8.3%",
      "\r8.3%",
      "\r8.4%",
      "\r8.5%",
      "\r8.6%",
      "\r8.7%",
      "\r8.8%",
      "\r8.8%",
      "\r8.9%",
      "\r9.0%",
      "\r9.1%",
      "\r9.2%",
      "\r9.3%",
      "\r9.3%",
      "\r9.4%",
      "\r9.5%",
      "\r9.6%",
      "\r9.7%",
      "\r9.8%",
      "\r9.8%",
      "\r9.9%",
      "\r10.0%",
      "\r10.1%",
      "\r10.2%",
      "\r10.2%",
      "\r10.3%",
      "\r10.4%",
      "\r10.5%",
      "\r10.6%",
      "\r10.7%",
      "\r10.7%",
      "\r10.8%",
      "\r10.9%",
      "\r11.0%",
      "\r11.1%",
      "\r11.2%",
      "\r11.2%",
      "\r11.3%",
      "\r11.4%",
      "\r11.5%",
      "\r11.6%",
      "\r11.7%",
      "\r11.7%",
      "\r11.8%",
      "\r11.9%",
      "\r12.0%",
      "\r12.1%",
      "\r12.1%",
      "\r12.2%",
      "\r12.3%",
      "\r12.4%",
      "\r12.5%",
      "\r12.6%",
      "\r12.6%",
      "\r12.7%",
      "\r12.8%",
      "\r12.9%",
      "\r13.0%",
      "\r13.1%",
      "\r13.1%",
      "\r13.2%",
      "\r13.3%",
      "\r13.4%",
      "\r13.5%",
      "\r13.6%",
      "\r13.6%",
      "\r13.7%",
      "\r13.8%",
      "\r13.9%",
      "\r14.0%",
      "\r14.0%",
      "\r14.1%",
      "\r14.2%",
      "\r14.3%",
      "\r14.4%",
      "\r14.5%",
      "\r14.5%",
      "\r14.6%",
      "\r14.7%",
      "\r14.8%",
      "\r14.9%",
      "\r15.0%",
      "\r15.0%",
      "\r15.1%",
      "\r15.2%",
      "\r15.3%",
      "\r15.4%",
      "\r15.5%",
      "\r15.5%",
      "\r15.6%",
      "\r15.7%",
      "\r15.8%",
      "\r15.9%",
      "\r16.0%",
      "\r16.0%",
      "\r16.1%",
      "\r16.2%",
      "\r16.3%",
      "\r16.4%",
      "\r16.4%",
      "\r16.5%",
      "\r16.6%",
      "\r16.7%",
      "\r16.8%",
      "\r16.9%",
      "\r16.9%",
      "\r17.0%",
      "\r17.1%",
      "\r17.2%",
      "\r17.3%",
      "\r17.4%",
      "\r17.4%",
      "\r17.5%",
      "\r17.6%",
      "\r17.7%",
      "\r17.8%",
      "\r17.9%",
      "\r17.9%",
      "\r18.0%",
      "\r18.1%",
      "\r18.2%",
      "\r18.3%",
      "\r18.3%",
      "\r18.4%",
      "\r18.5%",
      "\r18.6%",
      "\r18.7%",
      "\r18.8%",
      "\r18.8%",
      "\r18.9%",
      "\r19.0%",
      "\r19.1%",
      "\r19.2%",
      "\r19.3%",
      "\r19.3%",
      "\r19.4%",
      "\r19.5%",
      "\r19.6%",
      "\r19.7%",
      "\r19.8%",
      "\r19.8%",
      "\r19.9%",
      "\r20.0%",
      "\r20.1%",
      "\r20.2%",
      "\r20.2%",
      "\r20.3%",
      "\r20.4%",
      "\r20.5%",
      "\r20.6%",
      "\r20.7%",
      "\r20.7%",
      "\r20.8%",
      "\r20.9%",
      "\r21.0%",
      "\r21.1%",
      "\r21.2%",
      "\r21.2%",
      "\r21.3%",
      "\r21.4%",
      "\r21.5%",
      "\r21.6%",
      "\r21.7%",
      "\r21.7%",
      "\r21.8%",
      "\r21.9%",
      "\r22.0%",
      "\r22.1%",
      "\r22.1%",
      "\r22.2%",
      "\r22.3%",
      "\r22.4%",
      "\r22.5%",
      "\r22.6%",
      "\r22.6%",
      "\r22.7%",
      "\r22.8%",
      "\r22.9%",
      "\r23.0%",
      "\r23.1%",
      "\r23.1%",
      "\r23.2%",
      "\r23.3%",
      "\r23.4%",
      "\r23.5%",
      "\r23.6%",
      "\r23.6%",
      "\r23.7%",
      "\r23.8%",
      "\r23.9%",
      "\r24.0%",
      "\r24.0%",
      "\r24.1%",
      "\r24.2%",
      "\r24.3%",
      "\r24.4%",
      "\r24.5%",
      "\r24.5%",
      "\r24.6%",
      "\r24.7%",
      "\r24.8%",
      "\r24.9%",
      "\r25.0%",
      "\r25.0%",
      "\r25.1%",
      "\r25.2%",
      "\r25.3%",
      "\r25.4%",
      "\r25.5%",
      "\r25.5%",
      "\r25.6%",
      "\r25.7%",
      "\r25.8%",
      "\r25.9%",
      "\r26.0%",
      "\r26.0%",
      "\r26.1%",
      "\r26.2%",
      "\r26.3%",
      "\r26.4%",
      "\r26.4%",
      "\r26.5%",
      "\r26.6%",
      "\r26.7%",
      "\r26.8%",
      "\r26.9%",
      "\r26.9%",
      "\r27.0%",
      "\r27.1%",
      "\r27.2%",
      "\r27.3%",
      "\r27.4%",
      "\r27.4%",
      "\r27.5%",
      "\r27.6%",
      "\r27.7%",
      "\r27.8%",
      "\r27.9%",
      "\r27.9%",
      "\r28.0%",
      "\r28.1%",
      "\r28.2%",
      "\r28.3%",
      "\r28.3%",
      "\r28.4%",
      "\r28.5%",
      "\r28.6%",
      "\r28.7%",
      "\r28.8%",
      "\r28.8%",
      "\r28.9%",
      "\r29.0%",
      "\r29.1%",
      "\r29.2%",
      "\r29.3%",
      "\r29.3%",
      "\r29.4%",
      "\r29.5%",
      "\r29.6%",
      "\r29.7%",
      "\r29.8%",
      "\r29.8%",
      "\r29.9%",
      "\r30.0%",
      "\r30.1%",
      "\r30.2%",
      "\r30.2%",
      "\r30.3%",
      "\r30.4%",
      "\r30.5%",
      "\r30.6%",
      "\r30.7%",
      "\r30.7%",
      "\r30.8%",
      "\r30.9%",
      "\r31.0%",
      "\r31.1%",
      "\r31.2%",
      "\r31.2%",
      "\r31.3%",
      "\r31.4%",
      "\r31.5%",
      "\r31.6%",
      "\r31.7%",
      "\r31.7%",
      "\r31.8%",
      "\r31.9%",
      "\r32.0%",
      "\r32.1%",
      "\r32.1%",
      "\r32.2%",
      "\r32.3%",
      "\r32.4%",
      "\r32.5%",
      "\r32.6%",
      "\r32.6%",
      "\r32.7%",
      "\r32.8%",
      "\r32.9%",
      "\r33.0%",
      "\r33.1%",
      "\r33.1%",
      "\r33.2%",
      "\r33.3%",
      "\r33.4%",
      "\r33.5%",
      "\r33.6%",
      "\r33.6%",
      "\r33.7%",
      "\r33.8%",
      "\r33.9%",
      "\r34.0%",
      "\r34.0%",
      "\r34.1%",
      "\r34.2%",
      "\r34.3%",
      "\r34.4%",
      "\r34.5%",
      "\r34.5%",
      "\r34.6%",
      "\r34.7%",
      "\r34.8%",
      "\r34.9%",
      "\r35.0%",
      "\r35.0%",
      "\r35.1%",
      "\r35.2%",
      "\r35.3%",
      "\r35.4%",
      "\r35.5%",
      "\r35.5%",
      "\r35.6%",
      "\r35.7%",
      "\r35.8%",
      "\r35.9%",
      "\r36.0%",
      "\r36.0%",
      "\r36.1%",
      "\r36.2%",
      "\r36.3%",
      "\r36.4%",
      "\r36.4%",
      "\r36.5%",
      "\r36.6%",
      "\r36.7%",
      "\r36.8%",
      "\r36.9%",
      "\r36.9%",
      "\r37.0%",
      "\r37.1%",
      "\r37.2%",
      "\r37.3%",
      "\r37.4%",
      "\r37.4%",
      "\r37.5%",
      "\r37.6%",
      "\r37.7%",
      "\r37.8%",
      "\r37.9%",
      "\r37.9%",
      "\r38.0%",
      "\r38.1%",
      "\r38.2%",
      "\r38.3%",
      "\r38.3%",
      "\r38.4%",
      "\r38.5%",
      "\r38.6%",
      "\r38.7%",
      "\r38.8%",
      "\r38.8%",
      "\r38.9%",
      "\r39.0%",
      "\r39.1%",
      "\r39.2%",
      "\r39.3%",
      "\r39.3%",
      "\r39.4%",
      "\r39.5%",
      "\r39.6%",
      "\r39.7%",
      "\r39.8%",
      "\r39.8%",
      "\r39.9%",
      "\r40.0%",
      "\r40.1%",
      "\r40.2%",
      "\r40.2%",
      "\r40.3%",
      "\r40.4%",
      "\r40.5%",
      "\r40.6%",
      "\r40.7%",
      "\r40.7%",
      "\r40.8%",
      "\r40.9%",
      "\r41.0%",
      "\r41.1%",
      "\r41.2%",
      "\r41.2%",
      "\r41.3%",
      "\r41.4%",
      "\r41.5%",
      "\r41.6%",
      "\r41.7%",
      "\r41.7%",
      "\r41.8%",
      "\r41.9%",
      "\r42.0%",
      "\r42.1%",
      "\r42.1%",
      "\r42.2%",
      "\r42.3%",
      "\r42.4%",
      "\r42.5%",
      "\r42.6%",
      "\r42.6%",
      "\r42.7%",
      "\r42.8%",
      "\r42.9%",
      "\r43.0%",
      "\r43.1%",
      "\r43.1%",
      "\r43.2%",
      "\r43.3%",
      "\r43.4%",
      "\r43.5%",
      "\r43.6%",
      "\r43.6%",
      "\r43.7%",
      "\r43.8%",
      "\r43.9%",
      "\r44.0%",
      "\r44.0%",
      "\r44.1%",
      "\r44.2%",
      "\r44.3%",
      "\r44.4%",
      "\r44.5%",
      "\r44.5%",
      "\r44.6%",
      "\r44.7%",
      "\r44.8%",
      "\r44.9%",
      "\r45.0%",
      "\r45.0%",
      "\r45.1%",
      "\r45.2%",
      "\r45.3%",
      "\r45.4%",
      "\r45.5%",
      "\r45.5%",
      "\r45.6%",
      "\r45.7%",
      "\r45.8%",
      "\r45.9%",
      "\r45.9%",
      "\r46.0%",
      "\r46.1%",
      "\r46.2%",
      "\r46.3%",
      "\r46.4%",
      "\r46.4%",
      "\r46.5%",
      "\r46.6%",
      "\r46.7%",
      "\r46.8%",
      "\r46.9%",
      "\r46.9%",
      "\r47.0%",
      "\r47.1%",
      "\r47.2%",
      "\r47.3%",
      "\r47.4%",
      "\r47.4%",
      "\r47.5%",
      "\r47.6%",
      "\r47.7%",
      "\r47.8%",
      "\r47.9%",
      "\r47.9%",
      "\r48.0%",
      "\r48.1%",
      "\r48.2%",
      "\r48.3%",
      "\r48.3%",
      "\r48.4%",
      "\r48.5%",
      "\r48.6%",
      "\r48.7%",
      "\r48.8%",
      "\r48.8%",
      "\r48.9%",
      "\r49.0%",
      "\r49.1%",
      "\r49.2%",
      "\r49.3%",
      "\r49.3%",
      "\r49.4%",
      "\r49.5%",
      "\r49.6%",
      "\r49.7%",
      "\r49.8%",
      "\r49.8%",
      "\r49.9%",
      "\r50.0%",
      "\r50.1%",
      "\r50.2%",
      "\r50.2%",
      "\r50.3%",
      "\r50.4%",
      "\r50.5%",
      "\r50.6%",
      "\r50.7%",
      "\r50.7%",
      "\r50.8%",
      "\r50.9%",
      "\r51.0%",
      "\r51.1%",
      "\r51.2%",
      "\r51.2%",
      "\r51.3%",
      "\r51.4%",
      "\r51.5%",
      "\r51.6%",
      "\r51.7%",
      "\r51.7%",
      "\r51.8%",
      "\r51.9%",
      "\r52.0%",
      "\r52.1%",
      "\r52.1%",
      "\r52.2%",
      "\r52.3%",
      "\r52.4%",
      "\r52.5%",
      "\r52.6%",
      "\r52.6%",
      "\r52.7%",
      "\r52.8%",
      "\r52.9%",
      "\r53.0%",
      "\r53.1%",
      "\r53.1%",
      "\r53.2%",
      "\r53.3%",
      "\r53.4%",
      "\r53.5%",
      "\r53.6%",
      "\r53.6%",
      "\r53.7%",
      "\r53.8%",
      "\r53.9%",
      "\r54.0%",
      "\r54.0%",
      "\r54.1%",
      "\r54.2%",
      "\r54.3%",
      "\r54.4%",
      "\r54.5%",
      "\r54.5%",
      "\r54.6%",
      "\r54.7%",
      "\r54.8%",
      "\r54.9%",
      "\r55.0%",
      "\r55.0%",
      "\r55.1%",
      "\r55.2%",
      "\r55.3%",
      "\r55.4%",
      "\r55.5%",
      "\r55.5%",
      "\r55.6%",
      "\r55.7%",
      "\r55.8%",
      "\r55.9%",
      "\r55.9%",
      "\r56.0%",
      "\r56.1%",
      "\r56.2%",
      "\r56.3%",
      "\r56.4%",
      "\r56.4%",
      "\r56.5%",
      "\r56.6%",
      "\r56.7%",
      "\r56.8%",
      "\r56.9%",
      "\r56.9%",
      "\r57.0%",
      "\r57.1%",
      "\r57.2%",
      "\r57.3%",
      "\r57.4%",
      "\r57.4%",
      "\r57.5%",
      "\r57.6%",
      "\r57.7%",
      "\r57.8%",
      "\r57.9%",
      "\r57.9%",
      "\r58.0%",
      "\r58.1%",
      "\r58.2%",
      "\r58.3%",
      "\r58.3%",
      "\r58.4%",
      "\r58.5%",
      "\r58.6%",
      "\r58.7%",
      "\r58.8%",
      "\r58.8%",
      "\r58.9%",
      "\r59.0%",
      "\r59.1%",
      "\r59.2%",
      "\r59.3%",
      "\r59.3%",
      "\r59.4%",
      "\r59.5%",
      "\r59.6%",
      "\r59.7%",
      "\r59.8%",
      "\r59.8%",
      "\r59.9%",
      "\r60.0%",
      "\r60.1%",
      "\r60.2%",
      "\r60.2%",
      "\r60.3%",
      "\r60.4%",
      "\r60.5%",
      "\r60.6%",
      "\r60.7%",
      "\r60.7%",
      "\r60.8%",
      "\r60.9%",
      "\r61.0%",
      "\r61.1%",
      "\r61.2%",
      "\r61.2%",
      "\r61.3%",
      "\r61.4%",
      "\r61.5%",
      "\r61.6%",
      "\r61.7%",
      "\r61.7%",
      "\r61.8%",
      "\r61.9%",
      "\r62.0%",
      "\r62.1%",
      "\r62.1%",
      "\r62.2%",
      "\r62.3%",
      "\r62.4%",
      "\r62.5%",
      "\r62.6%",
      "\r62.6%",
      "\r62.7%",
      "\r62.8%",
      "\r62.9%",
      "\r63.0%",
      "\r63.1%",
      "\r63.1%",
      "\r63.2%",
      "\r63.3%",
      "\r63.4%",
      "\r63.5%",
      "\r63.6%",
      "\r63.6%",
      "\r63.7%",
      "\r63.8%",
      "\r63.9%",
      "\r64.0%",
      "\r64.0%",
      "\r64.1%",
      "\r64.2%",
      "\r64.3%",
      "\r64.4%",
      "\r64.5%",
      "\r64.5%",
      "\r64.6%",
      "\r64.7%",
      "\r64.8%",
      "\r64.9%",
      "\r65.0%",
      "\r65.0%",
      "\r65.1%",
      "\r65.2%",
      "\r65.3%",
      "\r65.4%",
      "\r65.5%",
      "\r65.5%",
      "\r65.6%",
      "\r65.7%",
      "\r65.8%",
      "\r65.9%",
      "\r65.9%",
      "\r66.0%",
      "\r66.1%",
      "\r66.2%",
      "\r66.3%",
      "\r66.4%",
      "\r66.4%",
      "\r66.5%",
      "\r66.6%",
      "\r66.7%",
      "\r66.8%",
      "\r66.9%",
      "\r66.9%",
      "\r67.0%",
      "\r67.1%",
      "\r67.2%",
      "\r67.3%",
      "\r67.4%",
      "\r67.4%",
      "\r67.5%",
      "\r67.6%",
      "\r67.7%",
      "\r67.8%",
      "\r67.9%",
      "\r67.9%",
      "\r68.0%",
      "\r68.1%",
      "\r68.2%",
      "\r68.3%",
      "\r68.3%",
      "\r68.4%",
      "\r68.5%",
      "\r68.6%",
      "\r68.7%",
      "\r68.8%",
      "\r68.8%",
      "\r68.9%",
      "\r69.0%",
      "\r69.1%",
      "\r69.2%",
      "\r69.3%",
      "\r69.3%",
      "\r69.4%",
      "\r69.5%",
      "\r69.6%",
      "\r69.7%",
      "\r69.8%",
      "\r69.8%",
      "\r69.9%",
      "\r70.0%",
      "\r70.1%",
      "\r70.2%",
      "\r70.2%",
      "\r70.3%",
      "\r70.4%",
      "\r70.5%",
      "\r70.6%",
      "\r70.7%",
      "\r70.7%",
      "\r70.8%",
      "\r70.9%",
      "\r71.0%",
      "\r71.1%",
      "\r71.2%",
      "\r71.2%",
      "\r71.3%",
      "\r71.4%",
      "\r71.5%",
      "\r71.6%",
      "\r71.7%",
      "\r71.7%",
      "\r71.8%",
      "\r71.9%",
      "\r72.0%",
      "\r72.1%",
      "\r72.1%",
      "\r72.2%",
      "\r72.3%",
      "\r72.4%",
      "\r72.5%",
      "\r72.6%",
      "\r72.6%",
      "\r72.7%",
      "\r72.8%",
      "\r72.9%",
      "\r73.0%",
      "\r73.1%",
      "\r73.1%",
      "\r73.2%",
      "\r73.3%",
      "\r73.4%",
      "\r73.5%",
      "\r73.6%",
      "\r73.6%",
      "\r73.7%",
      "\r73.8%",
      "\r73.9%",
      "\r74.0%",
      "\r74.0%",
      "\r74.1%",
      "\r74.2%",
      "\r74.3%",
      "\r74.4%",
      "\r74.5%",
      "\r74.5%",
      "\r74.6%",
      "\r74.7%",
      "\r74.8%",
      "\r74.9%",
      "\r75.0%",
      "\r75.0%",
      "\r75.1%",
      "\r75.2%",
      "\r75.3%",
      "\r75.4%",
      "\r75.5%",
      "\r75.5%",
      "\r75.6%",
      "\r75.7%",
      "\r75.8%",
      "\r75.9%",
      "\r75.9%",
      "\r76.0%",
      "\r76.1%",
      "\r76.2%",
      "\r76.3%",
      "\r76.4%",
      "\r76.4%",
      "\r76.5%",
      "\r76.6%",
      "\r76.7%",
      "\r76.8%",
      "\r76.9%",
      "\r76.9%",
      "\r77.0%",
      "\r77.1%",
      "\r77.2%",
      "\r77.3%",
      "\r77.4%",
      "\r77.4%",
      "\r77.5%",
      "\r77.6%",
      "\r77.7%",
      "\r77.8%",
      "\r77.9%",
      "\r77.9%",
      "\r78.0%",
      "\r78.1%",
      "\r78.2%",
      "\r78.3%",
      "\r78.3%",
      "\r78.4%",
      "\r78.5%",
      "\r78.6%",
      "\r78.7%",
      "\r78.8%",
      "\r78.8%",
      "\r78.9%",
      "\r79.0%",
      "\r79.1%",
      "\r79.2%",
      "\r79.3%",
      "\r79.3%",
      "\r79.4%",
      "\r79.5%",
      "\r79.6%",
      "\r79.7%",
      "\r79.8%",
      "\r79.8%",
      "\r79.9%",
      "\r80.0%",
      "\r80.1%",
      "\r80.2%",
      "\r80.2%",
      "\r80.3%",
      "\r80.4%",
      "\r80.5%",
      "\r80.6%",
      "\r80.7%",
      "\r80.7%",
      "\r80.8%",
      "\r80.9%",
      "\r81.0%",
      "\r81.1%",
      "\r81.2%",
      "\r81.2%",
      "\r81.3%",
      "\r81.4%",
      "\r81.5%",
      "\r81.6%",
      "\r81.7%",
      "\r81.7%",
      "\r81.8%",
      "\r81.9%",
      "\r82.0%",
      "\r82.1%",
      "\r82.1%",
      "\r82.2%",
      "\r82.3%",
      "\r82.4%",
      "\r82.5%",
      "\r82.6%",
      "\r82.6%",
      "\r82.7%",
      "\r82.8%",
      "\r82.9%",
      "\r83.0%",
      "\r83.1%",
      "\r83.1%",
      "\r83.2%",
      "\r83.3%",
      "\r83.4%",
      "\r83.5%",
      "\r83.6%",
      "\r83.6%",
      "\r83.7%",
      "\r83.8%",
      "\r83.9%",
      "\r84.0%",
      "\r84.0%",
      "\r84.1%",
      "\r84.2%",
      "\r84.3%",
      "\r84.4%",
      "\r84.5%",
      "\r84.5%",
      "\r84.6%",
      "\r84.7%",
      "\r84.8%",
      "\r84.9%",
      "\r85.0%",
      "\r85.0%",
      "\r85.1%",
      "\r85.2%",
      "\r85.3%",
      "\r85.4%",
      "\r85.5%",
      "\r85.5%",
      "\r85.6%",
      "\r85.7%",
      "\r85.8%",
      "\r85.9%",
      "\r85.9%",
      "\r86.0%",
      "\r86.1%",
      "\r86.2%",
      "\r86.3%",
      "\r86.4%",
      "\r86.4%",
      "\r86.5%",
      "\r86.6%",
      "\r86.7%",
      "\r86.8%",
      "\r86.9%",
      "\r86.9%",
      "\r87.0%",
      "\r87.1%",
      "\r87.2%",
      "\r87.3%",
      "\r87.4%",
      "\r87.4%",
      "\r87.5%",
      "\r87.6%",
      "\r87.7%",
      "\r87.8%",
      "\r87.9%",
      "\r87.9%",
      "\r88.0%",
      "\r88.1%",
      "\r88.2%",
      "\r88.3%",
      "\r88.3%",
      "\r88.4%",
      "\r88.5%",
      "\r88.6%",
      "\r88.7%",
      "\r88.8%",
      "\r88.8%",
      "\r88.9%",
      "\r89.0%",
      "\r89.1%",
      "\r89.2%",
      "\r89.3%",
      "\r89.3%",
      "\r89.4%",
      "\r89.5%",
      "\r89.6%",
      "\r89.7%",
      "\r89.8%",
      "\r89.8%",
      "\r89.9%",
      "\r90.0%",
      "\r90.1%",
      "\r90.2%",
      "\r90.2%",
      "\r90.3%",
      "\r90.4%",
      "\r90.5%",
      "\r90.6%",
      "\r90.7%",
      "\r90.7%",
      "\r90.8%",
      "\r90.9%",
      "\r91.0%",
      "\r91.1%",
      "\r91.2%",
      "\r91.2%",
      "\r91.3%",
      "\r91.4%",
      "\r91.5%",
      "\r91.6%",
      "\r91.7%",
      "\r91.7%",
      "\r91.8%",
      "\r91.9%",
      "\r92.0%",
      "\r92.1%",
      "\r92.1%",
      "\r92.2%",
      "\r92.3%",
      "\r92.4%",
      "\r92.5%",
      "\r92.6%",
      "\r92.6%",
      "\r92.7%",
      "\r92.8%",
      "\r92.9%",
      "\r93.0%",
      "\r93.1%",
      "\r93.1%",
      "\r93.2%",
      "\r93.3%",
      "\r93.4%",
      "\r93.5%",
      "\r93.6%",
      "\r93.6%",
      "\r93.7%",
      "\r93.8%",
      "\r93.9%",
      "\r94.0%",
      "\r94.0%",
      "\r94.1%",
      "\r94.2%",
      "\r94.3%",
      "\r94.4%",
      "\r94.5%",
      "\r94.5%",
      "\r94.6%",
      "\r94.7%",
      "\r94.8%",
      "\r94.9%",
      "\r95.0%",
      "\r95.0%",
      "\r95.1%",
      "\r95.2%",
      "\r95.3%",
      "\r95.4%",
      "\r95.5%",
      "\r95.5%",
      "\r95.6%",
      "\r95.7%",
      "\r95.8%",
      "\r95.9%",
      "\r95.9%",
      "\r96.0%",
      "\r96.1%",
      "\r96.2%",
      "\r96.3%",
      "\r96.4%",
      "\r96.4%",
      "\r96.5%",
      "\r96.6%",
      "\r96.7%",
      "\r96.8%",
      "\r96.9%",
      "\r96.9%",
      "\r97.0%",
      "\r97.1%",
      "\r97.2%",
      "\r97.3%",
      "\r97.4%",
      "\r97.4%",
      "\r97.5%",
      "\r97.6%",
      "\r97.7%",
      "\r97.8%",
      "\r97.9%",
      "\r97.9%",
      "\r98.0%",
      "\r98.1%",
      "\r98.2%",
      "\r98.3%",
      "\r98.3%",
      "\r98.4%",
      "\r98.5%",
      "\r98.6%",
      "\r98.7%",
      "\r98.8%",
      "\r98.8%",
      "\r98.9%",
      "\r99.0%",
      "\r99.1%",
      "\r99.2%",
      "\r99.3%",
      "\r99.3%",
      "\r99.4%",
      "\r99.5%",
      "\r99.6%",
      "\r99.7%",
      "\r99.8%",
      "\r99.8%",
      "\r99.9%",
      "\r100.0%",
      "\r100.1%",
      "\r0.0%",
      "\r28.4%",
      "\r56.7%",
      "\r85.1%",
      "\r113.5%",
      "\r0.0%",
      "\r0.5%",
      "\r1.0%",
      "\r1.5%",
      "\r2.0%",
      "\r2.5%",
      "\r3.0%",
      "\r3.5%",
      "\r4.0%",
      "\r4.5%",
      "\r5.0%",
      "\r5.5%",
      "\r6.0%",
      "\r6.5%",
      "\r7.0%",
      "\r7.5%",
      "\r7.9%",
      "\r8.4%",
      "\r8.9%",
      "\r9.4%",
      "\r9.9%",
      "\r10.4%",
      "\r10.9%",
      "\r11.4%",
      "\r11.9%",
      "\r12.4%",
      "\r12.9%",
      "\r13.4%",
      "\r13.9%",
      "\r14.4%",
      "\r14.9%",
      "\r15.4%",
      "\r15.9%",
      "\r16.4%",
      "\r16.9%",
      "\r17.4%",
      "\r17.9%",
      "\r18.4%",
      "\r18.9%",
      "\r19.4%",
      "\r19.9%",
      "\r20.4%",
      "\r20.9%",
      "\r21.4%",
      "\r21.9%",
      "\r22.4%",
      "\r22.9%",
      "\r23.4%",
      "\r23.8%",
      "\r24.3%",
      "\r24.8%",
      "\r25.3%",
      "\r25.8%",
      "\r26.3%",
      "\r26.8%",
      "\r27.3%",
      "\r27.8%",
      "\r28.3%",
      "\r28.8%",
      "\r29.3%",
      "\r29.8%",
      "\r30.3%",
      "\r30.8%",
      "\r31.3%",
      "\r31.8%",
      "\r32.3%",
      "\r32.8%",
      "\r33.3%",
      "\r33.8%",
      "\r34.3%",
      "\r34.8%",
      "\r35.3%",
      "\r35.8%",
      "\r36.3%",
      "\r36.8%",
      "\r37.3%",
      "\r37.8%",
      "\r38.3%",
      "\r38.8%",
      "\r39.2%",
      "\r39.7%",
      "\r40.2%",
      "\r40.7%",
      "\r41.2%",
      "\r41.7%",
      "\r42.2%",
      "\r42.7%",
      "\r43.2%",
      "\r43.7%",
      "\r44.2%",
      "\r44.7%",
      "\r45.2%",
      "\r45.7%",
      "\r46.2%",
      "\r46.7%",
      "\r47.2%",
      "\r47.7%",
      "\r48.2%",
      "\r48.7%",
      "\r49.2%",
      "\r49.7%",
      "\r50.2%",
      "\r50.7%",
      "\r51.2%",
      "\r51.7%",
      "\r52.2%",
      "\r52.7%",
      "\r53.2%",
      "\r53.7%",
      "\r54.2%",
      "\r54.7%",
      "\r55.1%",
      "\r55.6%",
      "\r56.1%",
      "\r56.6%",
      "\r57.1%",
      "\r57.6%",
      "\r58.1%",
      "\r58.6%",
      "\r59.1%",
      "\r59.6%",
      "\r60.1%",
      "\r60.6%",
      "\r61.1%",
      "\r61.6%",
      "\r62.1%",
      "\r62.6%",
      "\r63.1%",
      "\r63.6%",
      "\r64.1%",
      "\r64.6%",
      "\r65.1%",
      "\r65.6%",
      "\r66.1%",
      "\r66.6%",
      "\r67.1%",
      "\r67.6%",
      "\r68.1%",
      "\r68.6%",
      "\r69.1%",
      "\r69.6%",
      "\r70.1%",
      "\r70.5%",
      "\r71.0%",
      "\r71.5%",
      "\r72.0%",
      "\r72.5%",
      "\r73.0%",
      "\r73.5%",
      "\r74.0%",
      "\r74.5%",
      "\r75.0%",
      "\r75.5%",
      "\r76.0%",
      "\r76.5%",
      "\r77.0%",
      "\r77.5%",
      "\r78.0%",
      "\r78.5%",
      "\r79.0%",
      "\r79.5%",
      "\r80.0%",
      "\r80.5%",
      "\r81.0%",
      "\r81.5%",
      "\r82.0%",
      "\r82.5%",
      "\r83.0%",
      "\r83.5%",
      "\r84.0%",
      "\r84.5%",
      "\r85.0%",
      "\r85.5%",
      "\r86.0%",
      "\r86.4%",
      "\r86.9%",
      "\r87.4%",
      "\r87.9%",
      "\r88.4%",
      "\r88.9%",
      "\r89.4%",
      "\r89.9%",
      "\r90.4%",
      "\r90.9%",
      "\r91.4%",
      "\r91.9%",
      "\r92.4%",
      "\r92.9%",
      "\r93.4%",
      "\r93.9%",
      "\r94.4%",
      "\r94.9%",
      "\r95.4%",
      "\r95.9%",
      "\r96.4%",
      "\r96.9%",
      "\r97.4%",
      "\r97.9%",
      "\r98.4%",
      "\r98.9%",
      "\r99.4%",
      "\r99.9%",
      "\r100.4%",
      "\r0.0%",
      "\r180.4%"
     ],
     "output_type": "stream"
    }
   ]
  }
 ]
}